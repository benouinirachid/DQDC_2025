# -*- coding: utf-8 -*-
"""Module 4 - data standardization and transformation_updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uqKkVtDUIIcZdYI7Oi7zoXebH0dOGEle

# 1 - Normalization
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.datasets import fetch_california_housing
X, y = fetch_california_housing(return_X_y=True, as_frame=True)
X

X.hist(bins=30, figsize=(12, 12))
plt.show()

# Perform a min-max scaling on MedInc variable , plot the histogram before and after

import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

# Create a MinMaxScaler object
scaler = MinMaxScaler()

# Fit and transform the data using the scaler
scaled_MedInc = scaler.fit_transform(X[['MedInc']])

# Plot the histogram before scaling
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(X['MedInc'], bins=30)
plt.title('Original MedInc Distribution')
plt.xlabel('MedInc')
plt.ylabel('Frequency')

# Plot the histogram after scaling
plt.subplot(1, 2, 2)
plt.hist(scaled_MedInc, bins=30)
plt.title('Scaled MedInc Distribution')
plt.xlabel('Scaled MedInc')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# perform a Standard scaling on HouseAge variable , plot the histogram before and after

import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit and transform the data using the scaler
scaled_HouseAge = scaler.fit_transform(X[['HouseAge']])

# Plot the histogram before scaling
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(X['HouseAge'], bins=30)
plt.title('Original HouseAge Distribution')
plt.xlabel('HouseAge')
plt.ylabel('Frequency')

# Plot the histogram after scaling
plt.subplot(1, 2, 2)
plt.hist(scaled_HouseAge, bins=30)
plt.title('Scaled HouseAge Distribution')
plt.xlabel('Scaled HouseAge')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# prompt: Using data frame X: perform l2 Normalization on Population variable
import matplotlib.pyplot as plt
# L2 normalization on 'Population'
from sklearn.preprocessing import Normalizer, normalize

# Perform L2 normalization
scaler = Normalizer()

# Fit and transform the data using the scaler
scaled_Population = scaler.fit_transform(X[['Population']])

x_array = np.array(X['HouseAge'])
print("HouseAge array: ",x_array)

normalized_arr = normalize([x_array])
print("Normalized HouseAge array: ",normalized_arr)

# prompt: Using data frame X: perform RobustScaler on Population variable , plot the histogram before and after

import matplotlib.pyplot as plt
# L2 normalization on 'Population'
from sklearn.preprocessing import RobustScaler

# Perform L2 normalization
scaler = RobustScaler()

# Fit and transform the data using the scaler
scaled_Population = scaler.fit_transform(X[['Population']])

# Plot the histogram before scaling
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(X['Population'], bins=30)
plt.title('Original Population Distribution')
plt.xlabel('Population')
plt.ylabel('Frequency')

# Plot the histogram after scaling
plt.subplot(1, 2, 2)
plt.hist(scaled_Population, bins=30)
plt.title('Scaled Population Distribution')
plt.xlabel('Scaled Population')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

"""# 2 - Categorical Encoding

## One Hot Encoder
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder
import matplotlib.pyplot as plt

# Create a sample dataset
data = {
    'id': [1, 2, 3, 4, 5, 6],
    'color': ['red', 'blue', 'green', 'red', 'red', 'blue'],
    'size': ['small', 'medium', 'medium', 'large', 'small', 'large']
}

df = pd.DataFrame(data)
df

encoder = OneHotEncoder(sparse_output=False)
encoded_features = encoder.fit_transform(df[['color', 'size']])

# Get feature names from encoder
feature_names = encoder.get_feature_names_out(['color', 'size'])

# Create DataFrame with encoded features
df_encoded_sk = pd.DataFrame(encoded_features, columns=feature_names)
df_encoded_sk = pd.concat([df['id'], df_encoded_sk], axis=1)
df_encoded_sk

"""## Label Encoder"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

data = {
    'id': [1, 2, 3, 4, 5, 6],
    'color': ['red', 'blue', 'green', 'red', 'green', 'blue'],
    'size': ['small', 'medium', 'medium', 'large', 'small', 'large'],
    'quality': ['low', 'medium', 'high', 'medium', 'high', 'low']
}

df = pd.DataFrame(data)
df

df_label = df.copy()
color_encoder = LabelEncoder()
size_encoder = LabelEncoder()
quality_encoder = LabelEncoder()

df_label['color_encoded'] = color_encoder.fit_transform(df_label['color'])
df_label['size_encoded'] = size_encoder.fit_transform(df_label['size'])
df_label['quality_encoded'] = quality_encoder.fit_transform(df_label['quality'])

df_label

color_encoder.inverse_transform([0, 1, 2])

"""# 3 - Numerical Variable Transformations"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True, as_frame=True)
X

X.hist(bins=30, figsize=(12, 12))
plt.show()

def diagnostic_plots(df, variable):
  plt.figure(figsize=(10,5))
  plt.subplot(1, 2, 1)
  df[variable].hist(bins=30)
  plt.title(f"Histogram of {variable}")
  plt.subplot(1, 2, 2)
  stats.probplot(df[variable], dist="norm", plot=plt)
  plt.title(f"Q-Q plot of {variable}")
  plt.show()

diagnostic_plots(X, "MedInc")

X_tf = X.copy()

vars = ["MedInc", "AveRooms", "AveBedrms", "Population"]

X["MedInc"] = np.log(X["MedInc"]+1)
diagnostic_plots(X, "MedInc")

diagnostic_plots(X, "MedInc")

diagnostic_plots(X, "AveOccup")

X_tf["AveOccup"] = np.reciprocal(X_tf["AveOccup"])

diagnostic_plots(X_tf, "AveOccup")

!pip install feature-engine

X.drop(labels=["Latitude", "Longitude"], axis=1, inplace=True)

X.hist(bins=30, figsize=(8, 8), layout=(3, 3))
plt.show()

variables = list(X.columns)
def make_qqplot(df):
  plt.figure(figsize=(8, 5), constrained_layout=True)
  for i in range(6):
    # location in figure
    ax = plt.subplot(2, 3, i + 1)
    # variable to plot
    var = variables[i]
    # q-q plot
    stats.probplot((df[var]), dist="norm", plot=plt)
    # add variable name as title
    ax.set_title(var)
  plt.show()

make_qqplot(X)

from feature_engine.transformation import BoxCoxTransformer
bct = BoxCoxTransformer()
bct.fit(X)
X_tf = bct.transform(X)
bct.lambda_dict_

make_qqplot(X_tf)

X_tf.hist(bins=30, figsize=(8, 8), layout=(3, 3))
plt.show()

from feature_engine.transformation import YeoJohnsonTransformer
yjt = YeoJohnsonTransformer()
yjt.fit(X)
X_tf = yjt.transform(X)

make_qqplot(X_tf)

